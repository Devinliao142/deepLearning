{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peizhou.liao/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1671)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = '/home/peizhou.liao/deep_learning/Google/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASSES = 10\n",
    "RESHAPED = 784\n",
    "OPTIMIZER = SGD()\n",
    "BATCH_SIZE = 256\n",
    "NB_EPOCH = 100\n",
    "VERBOSE = 1\n",
    "N_HIDDEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 1.0085 - acc: 0.7243 - val_loss: 0.6841 - val_acc: 0.8016\n",
      "Epoch 2/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.6323 - acc: 0.8173 - val_loss: 0.6138 - val_acc: 0.8191\n",
      "Epoch 3/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.5856 - acc: 0.8299 - val_loss: 0.5845 - val_acc: 0.8251\n",
      "Epoch 4/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.5604 - acc: 0.8367 - val_loss: 0.5639 - val_acc: 0.8312\n",
      "Epoch 5/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.5428 - acc: 0.8415 - val_loss: 0.5498 - val_acc: 0.8346\n",
      "Epoch 6/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.5289 - acc: 0.8452 - val_loss: 0.5377 - val_acc: 0.8367\n",
      "Epoch 7/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.5173 - acc: 0.8478 - val_loss: 0.5281 - val_acc: 0.8392\n",
      "Epoch 8/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.5072 - acc: 0.8507 - val_loss: 0.5186 - val_acc: 0.8423\n",
      "Epoch 9/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.4981 - acc: 0.8530 - val_loss: 0.5101 - val_acc: 0.8443\n",
      "Epoch 10/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4899 - acc: 0.8551 - val_loss: 0.5032 - val_acc: 0.8476\n",
      "Epoch 11/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4823 - acc: 0.8572 - val_loss: 0.4961 - val_acc: 0.8502\n",
      "Epoch 12/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.4753 - acc: 0.8593 - val_loss: 0.4897 - val_acc: 0.8515\n",
      "Epoch 13/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4687 - acc: 0.8611 - val_loss: 0.4840 - val_acc: 0.8536\n",
      "Epoch 14/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4625 - acc: 0.8628 - val_loss: 0.4787 - val_acc: 0.8551\n",
      "Epoch 15/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.4566 - acc: 0.8646 - val_loss: 0.4734 - val_acc: 0.8567\n",
      "Epoch 16/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4510 - acc: 0.8663 - val_loss: 0.4691 - val_acc: 0.8579\n",
      "Epoch 17/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4456 - acc: 0.8678 - val_loss: 0.4644 - val_acc: 0.8592\n",
      "Epoch 18/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4405 - acc: 0.8694 - val_loss: 0.4605 - val_acc: 0.8607\n",
      "Epoch 19/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4357 - acc: 0.8710 - val_loss: 0.4563 - val_acc: 0.8621\n",
      "Epoch 20/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4309 - acc: 0.8725 - val_loss: 0.4525 - val_acc: 0.8622\n",
      "Epoch 21/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4265 - acc: 0.8737 - val_loss: 0.4491 - val_acc: 0.8636\n",
      "Epoch 22/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4221 - acc: 0.8751 - val_loss: 0.4462 - val_acc: 0.8644\n",
      "Epoch 23/100\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.4180 - acc: 0.8762 - val_loss: 0.4423 - val_acc: 0.8662\n",
      "Epoch 24/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4140 - acc: 0.8776 - val_loss: 0.4400 - val_acc: 0.8649\n",
      "Epoch 25/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.4101 - acc: 0.8787 - val_loss: 0.4366 - val_acc: 0.8660\n",
      "Epoch 26/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.4064 - acc: 0.8800 - val_loss: 0.4342 - val_acc: 0.8686\n",
      "Epoch 27/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.4028 - acc: 0.8811 - val_loss: 0.4316 - val_acc: 0.8684\n",
      "Epoch 28/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3993 - acc: 0.8820 - val_loss: 0.4285 - val_acc: 0.8685\n",
      "Epoch 29/100\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.3959 - acc: 0.8831 - val_loss: 0.4265 - val_acc: 0.8683\n",
      "Epoch 30/100\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.3927 - acc: 0.8841 - val_loss: 0.4239 - val_acc: 0.8710\n",
      "Epoch 31/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3895 - acc: 0.8848 - val_loss: 0.4220 - val_acc: 0.8705\n",
      "Epoch 32/100\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.3864 - acc: 0.8860 - val_loss: 0.4200 - val_acc: 0.8712\n",
      "Epoch 33/100\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.3835 - acc: 0.8868 - val_loss: 0.4184 - val_acc: 0.8718\n",
      "Epoch 34/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3806 - acc: 0.8877 - val_loss: 0.4168 - val_acc: 0.8728\n",
      "Epoch 35/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3779 - acc: 0.8887 - val_loss: 0.4144 - val_acc: 0.8730\n",
      "Epoch 36/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3751 - acc: 0.8896 - val_loss: 0.4129 - val_acc: 0.8738\n",
      "Epoch 37/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3725 - acc: 0.8905 - val_loss: 0.4107 - val_acc: 0.8728\n",
      "Epoch 38/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3700 - acc: 0.8911 - val_loss: 0.4097 - val_acc: 0.8740\n",
      "Epoch 39/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3675 - acc: 0.8921 - val_loss: 0.4078 - val_acc: 0.8745\n",
      "Epoch 40/100\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.3650 - acc: 0.8926 - val_loss: 0.4063 - val_acc: 0.8735\n",
      "Epoch 41/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3627 - acc: 0.8935 - val_loss: 0.4050 - val_acc: 0.8751\n",
      "Epoch 42/100\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.3604 - acc: 0.8940 - val_loss: 0.4032 - val_acc: 0.8750\n",
      "Epoch 43/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3581 - acc: 0.8945 - val_loss: 0.4025 - val_acc: 0.8754\n",
      "Epoch 44/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3559 - acc: 0.8953 - val_loss: 0.4005 - val_acc: 0.8771\n",
      "Epoch 45/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3538 - acc: 0.8958 - val_loss: 0.3997 - val_acc: 0.8763\n",
      "Epoch 46/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3517 - acc: 0.8966 - val_loss: 0.3989 - val_acc: 0.8776\n",
      "Epoch 47/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3496 - acc: 0.8970 - val_loss: 0.3965 - val_acc: 0.8781\n",
      "Epoch 48/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3476 - acc: 0.8980 - val_loss: 0.3964 - val_acc: 0.8779\n",
      "Epoch 49/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3456 - acc: 0.8983 - val_loss: 0.3943 - val_acc: 0.8793\n",
      "Epoch 50/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3437 - acc: 0.8990 - val_loss: 0.3943 - val_acc: 0.8791\n",
      "Epoch 51/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3418 - acc: 0.8994 - val_loss: 0.3923 - val_acc: 0.8803\n",
      "Epoch 52/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3399 - acc: 0.8998 - val_loss: 0.3925 - val_acc: 0.8797\n",
      "Epoch 53/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.3381 - acc: 0.9002 - val_loss: 0.3911 - val_acc: 0.8799\n",
      "Epoch 54/100\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.3362 - acc: 0.9007 - val_loss: 0.3893 - val_acc: 0.8800\n",
      "Epoch 55/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3345 - acc: 0.9015 - val_loss: 0.3881 - val_acc: 0.8809\n",
      "Epoch 56/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3328 - acc: 0.9021 - val_loss: 0.3867 - val_acc: 0.8807\n",
      "Epoch 57/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3310 - acc: 0.9023 - val_loss: 0.3862 - val_acc: 0.8818\n",
      "Epoch 58/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3293 - acc: 0.9031 - val_loss: 0.3855 - val_acc: 0.8816\n",
      "Epoch 59/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3277 - acc: 0.9034 - val_loss: 0.3848 - val_acc: 0.8825\n",
      "Epoch 60/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3261 - acc: 0.9037 - val_loss: 0.3836 - val_acc: 0.8829\n",
      "Epoch 61/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3244 - acc: 0.9045 - val_loss: 0.3832 - val_acc: 0.8833\n",
      "Epoch 62/100\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.3228 - acc: 0.9048 - val_loss: 0.3827 - val_acc: 0.8843\n",
      "Epoch 63/100\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.3213 - acc: 0.9052 - val_loss: 0.3812 - val_acc: 0.8846\n",
      "Epoch 64/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3198 - acc: 0.9057 - val_loss: 0.3804 - val_acc: 0.8842\n",
      "Epoch 65/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3182 - acc: 0.9059 - val_loss: 0.3804 - val_acc: 0.8851\n",
      "Epoch 66/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3167 - acc: 0.9062 - val_loss: 0.3782 - val_acc: 0.8851\n",
      "Epoch 67/100\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.3152 - acc: 0.9067 - val_loss: 0.3777 - val_acc: 0.8861\n",
      "Epoch 68/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3137 - acc: 0.9074 - val_loss: 0.3773 - val_acc: 0.8864\n",
      "Epoch 69/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3124 - acc: 0.9075 - val_loss: 0.3768 - val_acc: 0.8868\n",
      "Epoch 70/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3110 - acc: 0.9080 - val_loss: 0.3756 - val_acc: 0.8869\n",
      "Epoch 71/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3096 - acc: 0.9086 - val_loss: 0.3747 - val_acc: 0.8883\n",
      "Epoch 72/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3081 - acc: 0.9088 - val_loss: 0.3747 - val_acc: 0.8876\n",
      "Epoch 73/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3068 - acc: 0.9093 - val_loss: 0.3744 - val_acc: 0.8875\n",
      "Epoch 74/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3054 - acc: 0.9097 - val_loss: 0.3735 - val_acc: 0.8875\n",
      "Epoch 75/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3041 - acc: 0.9098 - val_loss: 0.3724 - val_acc: 0.8884\n",
      "Epoch 76/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3028 - acc: 0.9101 - val_loss: 0.3726 - val_acc: 0.8886\n",
      "Epoch 77/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3015 - acc: 0.9110 - val_loss: 0.3717 - val_acc: 0.8887\n",
      "Epoch 78/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.3003 - acc: 0.9110 - val_loss: 0.3717 - val_acc: 0.8890\n",
      "Epoch 79/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2990 - acc: 0.9112 - val_loss: 0.3710 - val_acc: 0.8893\n",
      "Epoch 80/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2977 - acc: 0.9117 - val_loss: 0.3705 - val_acc: 0.8905\n",
      "Epoch 81/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2965 - acc: 0.9122 - val_loss: 0.3696 - val_acc: 0.8904\n",
      "Epoch 82/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2953 - acc: 0.9124 - val_loss: 0.3691 - val_acc: 0.8913\n",
      "Epoch 83/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2940 - acc: 0.9126 - val_loss: 0.3687 - val_acc: 0.8916\n",
      "Epoch 84/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2928 - acc: 0.9129 - val_loss: 0.3677 - val_acc: 0.8898\n",
      "Epoch 85/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2916 - acc: 0.9136 - val_loss: 0.3681 - val_acc: 0.8907\n",
      "Epoch 86/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2905 - acc: 0.9136 - val_loss: 0.3672 - val_acc: 0.8916\n",
      "Epoch 87/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2893 - acc: 0.9142 - val_loss: 0.3663 - val_acc: 0.8920\n",
      "Epoch 88/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2881 - acc: 0.9144 - val_loss: 0.3670 - val_acc: 0.8925\n",
      "Epoch 89/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2870 - acc: 0.9148 - val_loss: 0.3672 - val_acc: 0.8920\n",
      "Epoch 90/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.2858 - acc: 0.9154 - val_loss: 0.3666 - val_acc: 0.8914\n",
      "Epoch 91/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2846 - acc: 0.9154 - val_loss: 0.3666 - val_acc: 0.8925\n",
      "Epoch 92/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2836 - acc: 0.9159 - val_loss: 0.3655 - val_acc: 0.8926\n",
      "Epoch 93/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2824 - acc: 0.9162 - val_loss: 0.3659 - val_acc: 0.8925\n",
      "Epoch 94/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2814 - acc: 0.9166 - val_loss: 0.3650 - val_acc: 0.8933\n",
      "Epoch 95/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2803 - acc: 0.9167 - val_loss: 0.3657 - val_acc: 0.8937\n",
      "Epoch 96/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2792 - acc: 0.9173 - val_loss: 0.3653 - val_acc: 0.8921\n",
      "Epoch 97/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2782 - acc: 0.9174 - val_loss: 0.3646 - val_acc: 0.8934\n",
      "Epoch 98/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.2771 - acc: 0.9178 - val_loss: 0.3645 - val_acc: 0.8927\n",
      "Epoch 99/100\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.2760 - acc: 0.9180 - val_loss: 0.3638 - val_acc: 0.8935\n",
      "Epoch 100/100\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.2750 - acc: 0.9183 - val_loss: 0.3642 - val_acc: 0.8936\n",
      "10000/10000 [==============================] - 0s 26us/step\n",
      "\n",
      "Test score: 0.1718628011584282\n",
      "Test accuracy: 0.9495\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=train_dataset, y=train_labels,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_data=(valid_dataset, valid_labels))\n",
    "score = model.evaluate(test_dataset, test_labels, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
